{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamshivamkumarsharma/Automated-Cow-Data-extraction-NLP-PROJECT-/blob/main/Automated_Cow_Data_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hello everyone, in this demonstration, I'll walk you through our project on Automated Cow Data Extraction.\n",
        "\n",
        "Step 1: Setting Up the Environment  \n",
        "First, let's ensure we have the necessary tools installed. We'll start by installing the pydub library for audio processing."
      ],
      "metadata": {
        "id": "ujI0ifFI5RFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jqt9-3YtA--",
        "outputId": "38c4ade7-974b-4fa1-fc63-7547f19903ad"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll mount Google Drive to access our project files."
      ],
      "metadata": {
        "id": "-U-OV9jw5ktX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpB2iooXkMzX",
        "outputId": "5020e688-d471-4890-9344-cc10e2226f45"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll install the SpeechRecognition library for speech recognition."
      ],
      "metadata": {
        "id": "-8DnUMdN5r7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWDT45NgcGkJ",
        "outputId": "2862a7bb-a9aa-42e5-ccc4-6efbede02540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Preprocessing the Audio\n",
        "\n",
        "We'll preprocess the audio to enhance transcription accuracy. This includes normalization, silence removal, and noise reduction."
      ],
      "metadata": {
        "id": "qSyLsxGf5z-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Tokenization:\n",
        "Tokenization is the process of splitting the transcribed text into individual words. We'll use the word_tokenize function from the nltk.tokenize module for this purpose.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zWTuNeFBcTTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re   #regular expression\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "# List of pre-stored cow IDs\n",
        "cow_ids = [\n",
        "    \"Rama\", \"67GB\",\n",
        "    \"Maneesha\", \"F29\",\n",
        "    \"XX35\", \"Mala\",\n",
        "    \"Lali\", \"MX90\",\n",
        "    \"Aarti\", \"babila\",\n",
        "    \"Usha\", \"Ragini\",\n",
        "    \"W-704\", \"Ranu\",\n",
        "    \"Mamta\", \"27 A\",\n",
        "    \"46 2 B\", \"55\",\n",
        "    \"Basanti\", \"297\"\n",
        "]\n",
        "\n",
        "# Tokenize the transcribed text into words\n",
        "tokens = word_tokenize(transcription)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nDPhHjSbs-3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff972f0-8281-4043-a7f1-61d0833550e5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function preprocess_text() to handle text preprocessing tasks."
      ],
      "metadata": {
        "id": "h7JNhiEE6OAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(transcription):\n",
        "    # Convert text to lowercase\n",
        "    transcription = transcription.lower()\n",
        "\n",
        "    # Replace \"w\" with \"W\" and add \"-\" before numbers\n",
        "    transcription = re.sub(r'\\b(w)\\b', 'W', transcription)\n",
        "    transcription = re.sub(r'(\\b\\d+\\b)', r'-\\1', transcription)\n",
        "\n",
        "    return transcription\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1FZprUZ7zpnx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognition (NER)** is a technique to identify and classify named entities in the text. In this case, we'll use spaCy for NER to identify cow IDs mentioned in the transcribed text."
      ],
      "metadata": {
        "id": "ebU1jk-SlZM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install numpy scipy\n",
        "!pip install noisereduce\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HqkQrzcn0Pi",
        "outputId": "b34c45ab-b63b-4f1c-fcd5-30729ffdf083"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: noisereduce in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (3.7.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from noisereduce) (0.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.66.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->noisereduce) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->noisereduce) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->noisereduce) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->noisereduce) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->noisereduce) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->noisereduce) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->noisereduce) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->noisereduce) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->noisereduce) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->noisereduce) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy model for NER\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "#`en_core_web_sm` is an English language multi-task Convolutional Neural Network(CNN) trained on OntoNotes.\n",
        "# Assigns context-specific token vectors, POS tags, dependency parse, and named entities  # POS-parts of speech\n",
        "\n",
        "# Use spaCy to perform NER on the transcribed text\n",
        "doc = nlp(transcription)\n"
      ],
      "metadata": {
        "id": "__P8cMvxlbkr"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k1BXCoftqK24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Steps:\n",
        "Normalize the Audio: Ensure the audio volume is consistent.\n",
        "Remove Silence: Remove long silences that might confuse the recognizer.\n",
        "Reduce Noise: Apply noise reduction to clean up the audio."
      ],
      "metadata": {
        "id": "ES-uPfuLoFpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/COW_PROJECT_NLP/\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5CQ-bXPqw6-",
        "outputId": "2b281e57-7272-4190-949e-ee17df1f31e9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/COW_PROJECT_NLP/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "import noisereduce as nr\n",
        "\n",
        "def preprocess_audio(input_file, output_file):\n",
        "    # Load the audio file\n",
        "    audio = AudioSegment.from_file(input_file)\n",
        "\n",
        "    # Normalize audio\n",
        "    audio = audio.apply_gain(-audio.max_dBFS)\n",
        "\n",
        "    # Remove silence\n",
        "    silence_threshold = -40  # in dB\n",
        "    chunks = audio.split_to_mono()\n",
        "    non_silent_chunks = [chunk for chunk in chunks if chunk.dBFS > silence_threshold]\n",
        "    processed_audio = sum(non_silent_chunks)\n",
        "\n",
        "    # Export the processed audio to a temporary file\n",
        "    temp_file = \"temp.wav\"\n",
        "    processed_audio.export(temp_file, format=\"wav\")\n",
        "\n",
        "    # Load the temp file using scipy\n",
        "    rate, data = wavfile.read(temp_file)\n",
        "\n",
        "    # Apply noise reduction\n",
        "    reduced_noise = nr.reduce_noise(y=data, sr=rate)\n",
        "\n",
        "    # Save the processed audio\n",
        "    wavfile.write(output_file, rate, reduced_noise)\n",
        "\n",
        "input_audio = \"/content/drive/MyDrive/COW PROJECT NLP/audio1.wav\"\n",
        "preprocessed_audio = \"/content/drive/MyDrive/COW PROJECT NLP/audio1.wav\"\n",
        "\n",
        "# Convert and preprocess the audio\n",
        "audio_segment = AudioSegment.from_file(input_audio)\n",
        "audio_segment.export(preprocessed_audio, format=\"wav\")\n",
        "preprocess_audio(preprocessed_audio, preprocessed_audio)\n"
      ],
      "metadata": {
        "id": "oZA-L2LFoFQv"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IBM Watson Speech to Text:** **Not using due to API issue **\n"
      ],
      "metadata": {
        "id": "iCqpaaaupIQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Fine-Tuning\n",
        "Google Speech Recognition:\n",
        "Adjust sensitivity to background noise:**"
      ],
      "metadata": {
        "id": "K7CHm4NSpfdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recognizer = sr.Recognizer()\n",
        "recognizer.energy_threshold = 300\n",
        "recognizer.dynamic_energy_threshold = True\n"
      ],
      "metadata": {
        "id": "JQNehC3rpk4_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transcribing the Audio\n",
        "\n",
        "We'll convert the audio file to WAV format and transcribe it using the Google Speech Recognition service."
      ],
      "metadata": {
        "id": "JbuxBtEH67ql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Data\n",
        "\n",
        "We'll extract cow IDs and milk yields from the transcription using NLP and regex."
      ],
      "metadata": {
        "id": "n0du9w6t63uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executing the Program\n",
        "\n",
        "We'll execute the program by converting the audio file to WAV format, transcribing it, and extracting data."
      ],
      "metadata": {
        "id": "CgVsmw5U6zN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import spacy\n",
        "import nltk\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def convert_to_wav(mp4_file):\n",
        "    audio = AudioSegment.from_file(mp4_file)\n",
        "    wav_file = os.path.splitext(mp4_file)[0] + \".wav\"\n",
        "    audio.export(wav_file, format=\"wav\")\n",
        "    return wav_file\n",
        "\n",
        "def transcribe_audio(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "    try:\n",
        "        transcription = recognizer.recognize_google(audio_data)\n",
        "        return transcription\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Google Speech Recognition could not understand the audio\"\n",
        "    except sr.RequestError as e:\n",
        "        return f\"Could not request results from Google Speech Recognition service; {e}\"\n",
        "\n",
        "def extract_data(transcription):\n",
        "    cow_ids = [\n",
        "        \"Rama\", \"67GB\", \"Maneesha\", \"F29\", \"XX35\", \"Mala\", \"Lali\", \"MX90\",\n",
        "        \"Aarti\", \"babila\", \"Usha\", \"Ragini\", \"00704\", \"Ranu\", \"Mamta\", \"27 A\",\n",
        "        \"46 2 B\", \"55\", \"Basanti\", \"297\"\n",
        "    ]\n",
        "\n",
        "    # Tokenize the transcribed text\n",
        "    tokens = word_tokenize(transcription)\n",
        "\n",
        "    # Load the spaCy model for NER\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(transcription)\n",
        "\n",
        "    identified_cow_ids = []\n",
        "    milk_yields = []\n",
        "\n",
        "    # Extract cow IDs using NER and regex\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == 'PERSON' and ent.text in cow_ids:\n",
        "            identified_cow_ids.append(ent.text)\n",
        "\n",
        "    for token in tokens:\n",
        "        if token in cow_ids:\n",
        "            identified_cow_ids.append(token)\n",
        "\n",
        "    # Extract milk yields using regex\n",
        "    milk_yield_patterns = re.findall(r'\\b(\\d+)\\s?Kg\\b', transcription, re.IGNORECASE)\n",
        "    milk_yields.extend(milk_yield_patterns)\n",
        "\n",
        "    # Return the extracted data\n",
        "    return identified_cow_ids, milk_yields\n",
        "\n",
        "# Convert mp4 to wav\n",
        "audio_file_mp4 = \"/content/drive/MyDrive/COW PROJECT NLP/audio1.mp4\"\n",
        "audio_file_wav = convert_to_wav(audio_file_mp4)\n",
        "\n",
        "# Transcribe the audio file\n",
        "transcription = transcribe_audio(audio_file_wav)\n",
        "print(\"Transcription:\", transcription)\n",
        "\n",
        "\n",
        "# Extract cow IDs and milk yields\n",
        "cow_ids, milk_yields = extract_data(transcription)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Identified Cow IDs:\", cow_ids)\n",
        "print(\"Identified Milk Yields in kg:\", milk_yields)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj-ruETTm3T6",
        "outputId": "b42fa310-cb51-4a2b-968c-9da4898ef19d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription: the yield of 00704 today is 8 kg\n",
            "Identified Cow IDs: ['00704']\n",
            "Identified Milk Yields in kg: ['8']\n"
          ]
        }
      ]
    }
  ]
}